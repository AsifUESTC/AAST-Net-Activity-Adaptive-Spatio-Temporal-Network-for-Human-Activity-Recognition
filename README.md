This repository contains the official implementation of our paper:
"AAST-Net: Activity Adaptive Spatio-Temporal Network for Human Activity Recognition", submitted to the Journal of Computer Vision and Image Understanding (CVIU).

📌 Overview
Human Activity Recognition (HAR) is a challenging task, especially when dealing with complex temporal dynamics. In this work, we propose AAST-Net, a novel deep learning architecture that adaptively captures both spatial and temporal dependencies in video sequences. Our approach integrates:

Adaptive Attention Mechanisms to enhance feature selection.
Spatio-Temporal Fusion for improved motion representation.
Multi-Scale Processing to handle variations in activity duration and complexity.


📝 Dataset
This model has been trained and tested on benchmark datasets such as HMDB51, UCF101 and UCF50. 

📊 Results
AAST-Net achieves state-of-the-art performance on multiple HAR datasets, showing significant improvement in activity recognition accuracy.

🔗 Citation
  author = {Asif Iqbal, et al.},
  title = {AAST-Net: Activity Adaptive Spatio-Temporal Network for Human Activity Recognition},
  journal = {Computer Vision and Image Understanding (CVIU)},
  year = {2024}
}
🛠️ Acknowledgments
We appreciate the contributions of our team and the open-source community. Special thanks to the authors of the benchmark datasets.

Note: Code will be provided after publication
