This repository contains the official implementation of our paper:
"AAST-Net: Activity Adaptive Spatio-Temporal Network for Human Activity Recognition", submitted to the Journal of Computer Vision and Image Understanding (CVIU).

ğŸ“Œ Overview
Human Activity Recognition (HAR) is a challenging task, especially when dealing with complex temporal dynamics. In this work, we propose AAST-Net, a novel deep learning architecture that adaptively captures both spatial and temporal dependencies in video sequences. Our approach integrates:

Adaptive Attention Mechanisms to enhance feature selection.
Spatio-Temporal Fusion for improved motion representation.
Multi-Scale Processing to handle variations in activity duration and complexity.


ğŸ“ Dataset
This model has been trained and tested on benchmark datasets such as HMDB51, UCF101 and UCF50. 

ğŸ“Š Results
AAST-Net achieves state-of-the-art performance on multiple HAR datasets, showing significant improvement in activity recognition accuracy.

ğŸ”— Citation
  author = {Asif Iqbal, et al.},
  title = {AAST-Net: Activity Adaptive Spatio-Temporal Network for Human Activity Recognition},
  journal = {Computer Vision and Image Understanding (CVIU)},
  year = {2024}
}
ğŸ› ï¸ Acknowledgments
We appreciate the contributions of our team and the open-source community. Special thanks to the authors of the benchmark datasets.

Note: Code will be provided after publication
